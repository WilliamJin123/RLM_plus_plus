Example of data:

{'id': '820080216', 'context_len': '1048576', 'dataset': 'metaphors', 'context_window_text': 'The following lines contain 19524 pairs of sentences, one per line. On each line, the first sentence contains a metaphorical statement and the second sentence (separated by " <--> ") contains a candidate literal interpretation of the statement. The literal interpretation can be classified as either correct or incorrect.\n\nYou will be asked to answer questions about the aggregate label statistics across all 19524 examples in this dataset. Do not try to guess, estimate, or approximate the result. C\n... [TRUNCATED. Total length: 2833590]', 'context_window_text_with_labels': 'The following lines contain 19524 pairs of sentences, one per line. On each line, the first sentence contains a metaphorical statement and the second sentence (separated by " <--> ") contains a candidate literal interpretation of the statement. The literal interpretation can be classified as either correct or incorrect.\n\nYou will be asked to answer questions about the aggregate label statistics across all 19524 examples in this dataset. Do not try to guess, estimate, or approximate the result. C\n... [TRUNCATED. Total length: 3204138]', 'question': "In the above data, which of the labels is the most common? Give your final answer in the form 'Label: answer' where answer is one of the labels: incorrect, correct.", 'task_group': 'counting', 'task': 'TASK_TYPE.MOST_FREQ', 'answer': "['correct']", 'answer_type': 'ANSWER_TYPE.LABEL', 'input_subset': 'False', 'num_labels': '2', 'context_window_id': '80016'}
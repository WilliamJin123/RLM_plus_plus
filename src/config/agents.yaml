rlm-agent:
  instructions:
  - You are an advanced Recursive Language Model (RLM++) designed to analyze massive
    documents.
  - The document is stored in a hierarchical tree of summaries and chunks in a database.
  - Your goal is to answer questions by navigating this tree.
  - 1. Start by calling 'inspect_document_hierarchy' to see the high-level overview.
  - 2. Use 'examine_summary_node' to drill down into interesting sections.
  - 4. Use 'search_summaries' if you are looking for specific keywords.
  - 5. Use 'PythonTools' if you need to perform calculations, loop through data, or verify facts across multiple chunks.
  - Be systematic and efficient. Use your tools to minimize the amount of raw text
    you read.
  tools:
  - RLMTools
  - PythonTools
  model:
    provider: cerebras
    model_id: zai-glm-4.7
    temperature: 0.0
  storage:
    db_path: data/rlm_agent.db
    session_table: rlm_agent_sessions
    add_history_to_context: false
    num_history_runs: 0
    read_chat_history: false

summarization-agent:
  instructions:
  - Summarize texts concisely, capturing key facts and entities.
  - They must encapsulate the main points clearly, and give enough context for a user to realize when they should read the full text.
  tools: []
  model:
    provider: openrouter
    model_id: mistralai/devstral-2512:free
    temperature: 0.0
smart-ingest-agent:
  instructions:
  - You are a smart text chunking assistant.
  - When asked to create summaries, make them concise but informative, capturing enough context that a user can decide if they need to read the full text.
  - When asked to find cut points, choose locations that preserve meaning and coherence.
  tools: []
  model:
    provider: cerebras
    model_id: llama-3.3-70b
    temperature: 0.0
  storage: 
    db_path: data/smart_ingest_agent.db
    session_table: ingest_sessions

chunk-analyzer-agent:
  instructions:
  - You are a precise reading assistant.
  - Read the provided context and answer the user's question accurately.
  - Do not add external information.
  tools: []
  model:
    provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
    temperature: 0.0
  storage: 
    db_path: data/chunk_analyzer_agent.db
    session_table: chunk_analysis_sessions

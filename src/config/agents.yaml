rlm-agent:
  instructions:
  - You are an advanced Recursive Language Model (RLM++) designed to analyze massive
    documents.
  - The document is stored in a hierarchical tree of summaries and chunks in a database.
  - Your goal is to answer questions by navigating this tree.
  - 1. Start by calling 'get_document_structure' to see the high-level overview.
  - 2. Use 'get_summary_children' to drill down into interesting sections.
  - 3. Use 'analyze_chunk(chunk_id, query)' to ask a sub-agent to find specific information
    within a raw text chunk (prevents context overflow).
  - 4. Use 'search_summaries' if you are looking for specific keywords.
  - 5. Use 'PythonTools' if you need to perform calculations, loop through data, or
    verify facts across multiple chunks.
  - DO NOT guess or hallucinate content. If the information is not in the document,
    say so.
  - Be systematic and efficient. Use your tools to minimize the amount of raw text
    you read.
  tools:
  - get_document_structure
  - get_summary_children
  - analyze_chunk
  - search_summaries
  - PythonTools
  model:
    provider: cerebras
    model_id: zai-glm-4.7
    temperature: 0.0
  storage:
    db_path: data/rlm_agent.db
    session_table: rlm_agent_sessions
    add_history_to_context: false
    num_history_runs: 5
    read_chat_history: false
  readonly_model: false

summarization-agent:
  instructions:
  - Summarize texts concisely, capturing key facts and entities.
  - They must encapsulate the main points clearly, and give enough context for a user to realize when they should read the full text.
  tools: []
  model:
    provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
    temperature: 0.0
  storage:
    db_path: data/sumarization_agent.db
    session_table: llama-3.3-70b
    add_history_to_context: false
    num_history_runs: 0
    read_chat_history: false
  readonly_model: true

smart-ingest-agent:
  instructions:
  - You are a smart text chunking assistant.
  - When asked to create summaries, make them concise but informative, capturing enough context that a user can decide if they need to read the full text.
  - When asked to find cut points, choose locations that preserve meaning and coherence.
  tools: []
  model:
    provider: cerebras
    model_id: llama-3.3-70b
    temperature: 0.0
  storage: null
  readonly_model: true

chunk-analyzer-agent:
  instructions:
  - You are a precise reading assistant.
  - Read the provided context and answer the user's question accurately.
  - Do not add external information.
  tools: []
  model:
    provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
    temperature: 0.0
  storage: null
  readonly_model: true

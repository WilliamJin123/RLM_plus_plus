rlm-agent:
  instructions:
  - You are an advanced Recursive Language Model (RLM++) designed to analyze massive
    documents.
  - The document is stored in a hierarchical tree of summaries and chunks in a database.
  - Your goal is to answer questions by navigating this tree.
  - 1. Start by calling 'inspect_document_hierarchy' to see the high-level overview.
  - 2. Use 'examine_summary_node' to drill down into interesting sections.
  - 4. Use 'search_summaries' if you are looking for specific keywords.
  - 5. Use 'PythonTools' if you need to perform calculations, loop through data, or verify facts across multiple chunks.
  - Be systematic and efficient. Use your tools to minimize the amount of raw text
    you read.
  tools:
  - RLMTools
  - PythonTools
  model:
    provider: cerebras
    model_id: zai-glm-4.7
    temperature: 0.0
  storage:
    db_path: data/rlm_agent.db
    session_table: rlm_agent_sessions
    add_history_to_context: false
    num_history_runs: 0
    read_chat_history: false

summarization-agent:
  instructions:
  - Summarize texts concisely, capturing key facts and entities.
  - They must encapsulate the main points clearly, and give enough context for a user to realize when they should read the full text.
  tools: []
  temperature: 0.0
  calls_per_model: 3
  models:
  # Cerebras models
  - provider: cerebras
    model_id: llama-3.3-70b
  - provider: cerebras
    model_id: qwen-3-32b
  - provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
  # OpenRouter models (>100k context, capable of summarization)
  - provider: openrouter
    model_id: meta-llama/llama-3.3-70b-instruct:free
  - provider: openrouter
    model_id: meta-llama/llama-3.1-405b-instruct:free
  - provider: openrouter
    model_id: qwen/qwen3-coder:free
  - provider: openrouter
    model_id: deepseek/deepseek-r1-0528:free
  - provider: openrouter
    model_id: google/gemini-2.0-flash-exp:free
  - provider: openrouter
    model_id: mistralai/devstral-2512:free
  - provider: openrouter
    model_id: nousresearch/hermes-3-llama-3.1-405b:free
  - provider: openrouter
    model_id: nvidia/nemotron-3-nano-30b-a3b:free
  - provider: openrouter
    model_id: google/gemma-3-27b-it:free
  - provider: openrouter
    model_id: tngtech/deepseek-r1t2-chimera:free

smart-ingest-agent:
  instructions:
  - You are a smart text chunking assistant.
  - When asked to create summaries, make them concise but informative, capturing enough context that a user can decide if they need to read the full text.
  - When asked to find cut points, choose locations that preserve meaning and coherence.
  tools: []
  temperature: 0.0
  calls_per_model: 3
  models:
  # Cerebras models
  - provider: cerebras
    model_id: llama-3.3-70b
  - provider: cerebras
    model_id: qwen-3-32b
  - provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
  # OpenRouter models (>100k context, capable of summarization)
  - provider: openrouter
    model_id: meta-llama/llama-3.3-70b-instruct:free
  - provider: openrouter
    model_id: meta-llama/llama-3.1-405b-instruct:free
  - provider: openrouter
    model_id: qwen/qwen3-coder:free
  - provider: openrouter
    model_id: deepseek/deepseek-r1-0528:free
  - provider: openrouter
    model_id: google/gemini-2.0-flash-exp:free
  - provider: openrouter
    model_id: mistralai/devstral-2512:free
  - provider: openrouter
    model_id: nousresearch/hermes-3-llama-3.1-405b:free
  - provider: openrouter
    model_id: nvidia/nemotron-3-nano-30b-a3b:free
  - provider: openrouter
    model_id: google/gemma-3-27b-it:free
  - provider: openrouter
    model_id: tngtech/deepseek-r1t2-chimera:free

chunk-analyzer-agent:
  instructions:
  - You are a precise reading assistant.
  - Read the provided context and answer the user's question accurately.
  - Do not add external information.
  tools: []
  model:
    provider: cerebras
    model_id: qwen-3-235b-a22b-instruct-2507
    temperature: 0.0